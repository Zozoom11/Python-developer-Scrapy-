Открываем проект, заходим в git_parse/git_parse/spiders открываем файл git_spider.py - видим нашего паука, на вход которого приходит link: "start_urls" (я понимаю что это хард код с вставкой ссылки, что не очень хорошо), запускаем нашего паука scrapy crawl "название паука" ,далее наши паук начинает собирать информацию, которая поступает в базу данных MongoDB, подключение к базе и запись информации реализована в файле pipelines.py

![dw]()
